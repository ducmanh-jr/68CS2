{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e996e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tham số w = [-2.85614925  1.72440695]\n",
      "Tham số b = -0.8893545389345123\n",
      "Xác suất P(y=1 | (6,2)) = 4.6676655260517145e-07\n",
      "Phương trình đường phân tách: x2 = 1.656 * x1 + 0.516\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ==== Dữ liệu ====\n",
    "X = np.array([\n",
    "    [1, 9],\n",
    "    [2, 6],\n",
    "    [2, 8],\n",
    "    [3, 9],\n",
    "    [2, 2],\n",
    "    [3, 3],\n",
    "    [4, 1],\n",
    "    [5, 2],\n",
    "    [5, 4],\n",
    "    [8, 1]\n",
    "], dtype=float)\n",
    "\n",
    "y = np.array([1, 1, 1, 1, 0, 0, 0, 0, 0, 0], dtype=float)\n",
    "\n",
    "N, d = X.shape\n",
    "\n",
    "# ==== Tham số ====\n",
    "w = np.zeros(d)   # w(0) = [0,0]\n",
    "b = 0.0           # b(0) = 0\n",
    "eta = 1e-3        # tốc độ học\n",
    "epochs = 100000   # số vòng lặp\n",
    "\n",
    "# ==== Hàm sigmoid ====\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# ==== Thuật toán Gradient Descent ====\n",
    "for t in range(epochs):\n",
    "    z = X.dot(w) + b\n",
    "    p = sigmoid(z)             # xác suất dự báo\n",
    "    error = p - y              # sai số\n",
    "    grad_w = (X.T.dot(error)) / N\n",
    "    grad_b = np.mean(error)\n",
    "    w -= eta * grad_w\n",
    "    b -= eta * grad_b\n",
    "\n",
    "# ==== Kết quả ====\n",
    "print(\"Tham số w =\", w)\n",
    "print(\"Tham số b =\", b)\n",
    "\n",
    "# 1) Xác suất điểm (6,2) thuộc lớp 1\n",
    "pt = np.array([6.0, 2.0])\n",
    "prob_pt = sigmoid(pt.dot(w) + b)\n",
    "print(\"Xác suất P(y=1 | (6,2)) =\", prob_pt)\n",
    "\n",
    "# 2) Đường phân tách: w1*x1 + w2*x2 + b = 0\n",
    "# => x2 = (-w1/w2)*x1 - b/w2\n",
    "slope = -w[0] / w[1]\n",
    "intercept = -b / w[1]\n",
    "print(\"Phương trình đường phân tách: x2 = %.3f * x1 + %.3f\" % (slope, intercept))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a2defad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thuật toán hội tụ: True sau 9 vòng lặp\n",
      "Tham số cuối cùng:\n",
      "   w = [-0.96960175  1.80486752]\n",
      "   b = -6.12177762654924\n",
      "Giá trị hàm mất mát = 0.03355928728594654\n",
      "\n",
      "Xác suất P(y=1 | (3,7)) = 0.9734932056414295\n",
      "Dự đoán lớp = 1\n",
      "\n",
      "Phương trình đường phân tách:\n",
      "   x2 = 0.537215 * x1 + 3.391816\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ======================\n",
    "# 1. DỮ LIỆU\n",
    "# ======================\n",
    "X = np.array([[1,9],[2,6],[2,8],[3,9],[2,2],\n",
    "              [3,3],[4,1],[5,2],[5,4],[8,1]], dtype=float)\n",
    "y = np.array([1,1,1,1,0,0,0,0,0,0], dtype=float)\n",
    "N, d = X.shape   # N=10, d=2 (số mẫu, số đặc trưng)\n",
    "\n",
    "# Thêm cột 1 để gom bias vào vector tham số (theta = [w1, w2, b])\n",
    "X_tilde = np.hstack([X, np.ones((N,1))])\n",
    "\n",
    "# ======================\n",
    "# 2. CÁC HÀM CƠ BẢN\n",
    "# ======================\n",
    "def sigmoid(z):\n",
    "    \"\"\"Hàm sigmoid: σ(z) = 1/(1+exp(-z))\"\"\"\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "def loss(theta, lambda_reg=1e-2):\n",
    "    \"\"\"\n",
    "    Hàm mất mát (Negative log-likelihood) có thêm L2 regularization.\n",
    "    Chỉ regularize w, không regularize bias.\n",
    "    \"\"\"\n",
    "    z = X_tilde.dot(theta)\n",
    "    p = sigmoid(z)\n",
    "    w = theta[:-1]\n",
    "    nll = -np.mean(y*np.log(p+1e-12) + (1-y)*np.log(1-p+1e-12))\n",
    "    reg = 0.5 * lambda_reg * np.dot(w, w)\n",
    "    return nll + reg\n",
    "\n",
    "def grad_and_hess(theta, lambda_reg=1e-2):\n",
    "    \"\"\"\n",
    "    Tính gradient và Hessian tại theta.\n",
    "    Gradient: g = 1/N * X^T (p - y) + lambda * w\n",
    "    Hessian: H = 1/N * X^T S X + lambda * I (trên phần w)\n",
    "    \"\"\"\n",
    "    z = X_tilde.dot(theta)\n",
    "    p = sigmoid(z)\n",
    "    grad = (X_tilde.T.dot(p - y)) / N\n",
    "    # chỉ regularize w (không regularize bias)\n",
    "    reg_vec = np.concatenate([lambda_reg * theta[:-1], [0.0]])\n",
    "    grad += reg_vec\n",
    "    # ma trận S = diag(p*(1-p))\n",
    "    S = p * (1 - p)\n",
    "    H = (X_tilde.T.dot(np.diag(S)).dot(X_tilde)) / N\n",
    "    # thêm lambda lên đường chéo phần w\n",
    "    H[:d, :d] += lambda_reg * np.eye(d)\n",
    "    return grad, H\n",
    "\n",
    "# ======================\n",
    "# 3. THUẬT TOÁN NEWTON-RAPHSON\n",
    "# ======================\n",
    "max_iter = 1000\n",
    "tol = 1e-6\n",
    "theta = np.zeros(d+1)  # khởi tạo w=(0,0), b=0\n",
    "converged = False\n",
    "\n",
    "for k in range(max_iter):\n",
    "    grad, H = grad_and_hess(theta)\n",
    "    # Giải hệ tuyến tính H * delta = grad\n",
    "    try:\n",
    "        delta = np.linalg.solve(H, grad)\n",
    "    except np.linalg.LinAlgError:\n",
    "        delta = np.linalg.pinv(H).dot(grad)\n",
    "    # Cập nhật: theta_new = theta - delta\n",
    "    theta_new = theta - delta\n",
    "    # Điều kiện dừng\n",
    "    if np.linalg.norm(theta_new - theta) < tol:\n",
    "        theta = theta_new\n",
    "        converged = True\n",
    "        break\n",
    "    theta = theta_new\n",
    "\n",
    "# ======================\n",
    "# 4. KẾT QUẢ CUỐI CÙNG\n",
    "# ======================\n",
    "w = theta[:-1]\n",
    "b = theta[-1]\n",
    "\n",
    "print(\"Thuật toán hội tụ:\", converged, \"sau\", k+1, \"vòng lặp\")\n",
    "print(\"Tham số cuối cùng:\")\n",
    "print(\"   w =\", w)\n",
    "print(\"   b =\", b)\n",
    "print(\"Giá trị hàm mất mát =\", loss(theta))\n",
    "\n",
    "# ======================\n",
    "# 5. DỰ BÁO ĐIỂM (3,7)\n",
    "# ======================\n",
    "pt = np.array([3.0, 7.0])\n",
    "prob_pt = sigmoid(pt.dot(w) + b)\n",
    "print(\"\\nXác suất P(y=1 | (3,7)) =\", prob_pt)\n",
    "print(\"Dự đoán lớp =\", int(prob_pt >= 0.5))\n",
    "\n",
    "# ======================\n",
    "# 6. ĐƯỜNG PHÂN TÁCH\n",
    "# ======================\n",
    "# Công thức: b + w1*x1 + w2*x2 = 0  =>  x2 = -(w1/w2)x1 - b/w2\n",
    "if abs(w[1]) > 1e-12:\n",
    "    slope = -w[0]/w[1]\n",
    "    intercept = -b/w[1]\n",
    "    print(\"\\nPhương trình đường phân tách:\")\n",
    "    print(\"   x2 = {:.6f} * x1 + {:.6f}\".format(slope, intercept))\n",
    "else:\n",
    "    print(\"\\nĐường phân tách gần như thẳng đứng tại x1 = {:.6f}\".format(-b/w[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c8e2ec",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2361be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
